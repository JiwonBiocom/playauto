{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL과 연동\n",
    "conn_ps = psycopg2.connect(\n",
    "    host=\"15.164.112.237\", \n",
    "    database=\"dify\", \n",
    "    user=\"difyuser\", \n",
    "    password=\"bico0218\"\n",
    ")\n",
    "\n",
    "conn_ps.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "cursor_ps = conn_ps.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT 마스터_SKU, 수량, 시점\n",
    "    FROM playauto_shipment_receipt\n",
    "    WHERE 입출고_여부 = '출고'\n",
    "    ORDER BY 마스터_SKU, 시점\n",
    "\"\"\"\n",
    "cursor_ps.execute(query)\n",
    "result = cursor_ps.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['마스터_SKU', '수량', '시점'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "print(df.head())\n",
    "print(f\"Unique SKUs: {df['마스터_SKU'].unique()}\")\n",
    "print(f\"Date range: {df['시점'].min()} to {df['시점'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all SKUs\n",
    "all_skus = ['VIT-C-1000', 'OMEGA-3-500', 'PROBIO-10B', 'VIT-D-5000', 'CALCIUM-MAG', 'ZINC-15', \n",
    "            'COLLAGEN-1K', 'LUTEIN-20', 'ENZYME', 'IRON-18', 'MULTI-VIT', 'ADRENALYZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed VIT-C-1000: 6 months, Total quantity: 1720\n",
      "Processed OMEGA-3-500: 6 months, Total quantity: 2463\n",
      "Processed PROBIO-10B: 6 months, Total quantity: 2454\n",
      "Processed VIT-D-5000: 6 months, Total quantity: 2298\n",
      "Processed CALCIUM-MAG: 6 months, Total quantity: 2646\n",
      "Processed ZINC-15: 6 months, Total quantity: 2826\n",
      "Processed COLLAGEN-1K: 6 months, Total quantity: 2321\n",
      "Processed LUTEIN-20: 6 months, Total quantity: 2088\n",
      "Warning: No data found for SKU ENZYME\n",
      "Processed IRON-18: 6 months, Total quantity: 2601\n",
      "Processed MULTI-VIT: 6 months, Total quantity: 2415\n",
      "Warning: No data found for SKU ADRENALYZE\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Preprocessing\n",
    "# Convert 시점 to datetime\n",
    "df['시점'] = pd.to_datetime(df['시점'])\n",
    "\n",
    "# Extract date only (remove time component)\n",
    "df['날짜'] = df['시점'].dt.date\n",
    "\n",
    "# Create monthly aggregation for better seasonality capture\n",
    "df['연월'] = df['시점'].dt.to_period('M')\n",
    "\n",
    "# Aggregate by SKU and month (monthly totals)\n",
    "df_monthly = df.groupby(['마스터_SKU', '연월'])['수량'].sum().reset_index()\n",
    "\n",
    "# Convert period to timestamp for modeling\n",
    "df_monthly['날짜'] = df_monthly['연월'].dt.to_timestamp()\n",
    "\n",
    "# Process each SKU individually\n",
    "sku_data_monthly = {}\n",
    "\n",
    "for sku in all_skus:\n",
    "    # Filter data for this SKU\n",
    "    sku_df = df_monthly[df_monthly['마스터_SKU'] == sku].copy()\n",
    "    \n",
    "    if len(sku_df) == 0:\n",
    "        print(f\"Warning: No data found for SKU {sku}\")\n",
    "        continue\n",
    "    \n",
    "    # Sort by date\n",
    "    sku_df = sku_df.sort_values('날짜')\n",
    "    \n",
    "    # Store monthly data\n",
    "    sku_data_monthly[sku] = sku_df\n",
    "    \n",
    "    print(f\"Processed {sku}: {len(sku_df)} months, Total quantity: {sku_df['수량'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train-Test Split Function\n",
    "def train_test_split_ts(data, test_months=3):\n",
    "    \"\"\"Split time series data preserving temporal order\"\"\"\n",
    "    if len(data) <= test_months:\n",
    "        return data, pd.DataFrame()\n",
    "    \n",
    "    train = data[:-test_months].copy()\n",
    "    test = data[-test_months:].copy()\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Enhanced ARIMA Model Training with proper seasonal handling\n",
    "def train_arima_seasonal(train_data, forecast_months, sku_name):\n",
    "    \"\"\"Train ARIMA model with seasonal components\"\"\"\n",
    "    try:\n",
    "        # Prepare data\n",
    "        y = train_data['수량'].values\n",
    "        \n",
    "        # For very short series, use simple forecast\n",
    "        if len(y) < 4:\n",
    "            # Use average with growth trend\n",
    "            base_avg = np.mean(y)\n",
    "            growth_rate = 0.05  # 5% monthly growth\n",
    "            forecast = []\n",
    "            for i in range(forecast_months):\n",
    "                forecast.append(base_avg * (1 + growth_rate * i))\n",
    "            return np.array(forecast), None\n",
    "        \n",
    "        # Check for stationarity\n",
    "        adf_result = adfuller(y)\n",
    "        d = 0 if adf_result[1] < 0.05 else 1\n",
    "        \n",
    "        # Determine seasonal pattern based on SKU characteristics\n",
    "        # VIT-C-1000 shows clear seasonal pattern\n",
    "        if sku_name == 'VIT-C-1000':\n",
    "            # Based on the data pattern: low in Feb, peak in Mar/Jul\n",
    "            # Use SARIMA with monthly seasonality\n",
    "            if len(y) >= 6:\n",
    "                # SARIMA model: (p,d,q)(P,D,Q)s\n",
    "                # s=6 for semi-annual pattern\n",
    "                model = ARIMA(y, order=(2,d,1), seasonal_order=(1,0,1,6))\n",
    "            else:\n",
    "                model = ARIMA(y, order=(1,d,1))\n",
    "        else:\n",
    "            # For other SKUs, use auto-determined parameters\n",
    "            if len(y) >= 12:\n",
    "                model = ARIMA(y, order=(2,d,2), seasonal_order=(1,0,1,12))\n",
    "            else:\n",
    "                model = ARIMA(y, order=(1,d,1))\n",
    "        \n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecast = model_fit.forecast(steps=forecast_months)\n",
    "        \n",
    "        # Apply seasonal adjustments for VIT-C-1000\n",
    "        if sku_name == 'VIT-C-1000':\n",
    "            # Based on historical pattern:\n",
    "            # Feb: low (base), Mar: +60%, Apr: +40%, May: +20%, Jun: +40%, Jul: +80%\n",
    "            # Aug-Oct should follow summer/fall pattern\n",
    "            last_month = train_data['연월'].iloc[-1].month\n",
    "            seasonal_factors = {\n",
    "                1: 0.9,   # Jan\n",
    "                2: 1.0,   # Feb (base)\n",
    "                3: 1.6,   # Mar\n",
    "                4: 1.4,   # Apr\n",
    "                5: 1.2,   # May\n",
    "                6: 1.4,   # Jun\n",
    "                7: 1.8,   # Jul\n",
    "                8: 1.7,   # Aug (maintain high summer demand)\n",
    "                9: 1.6,   # Sep (slight decrease)\n",
    "                10: 1.5,  # Oct (autumn immunity boost)\n",
    "                11: 1.4,  # Nov\n",
    "                12: 1.3   # Dec\n",
    "            }\n",
    "            \n",
    "            # Apply seasonal adjustment\n",
    "            adjusted_forecast = []\n",
    "            for i in range(forecast_months):\n",
    "                future_month = ((last_month + i) % 12) + 1\n",
    "                seasonal_factor = seasonal_factors.get(future_month, 1.0)\n",
    "                \n",
    "                # Blend model forecast with seasonal adjustment\n",
    "                base_forecast = forecast[i] if isinstance(forecast, np.ndarray) else forecast.iloc[i]\n",
    "                adjusted_value = base_forecast * 0.7 + (np.mean(y) * seasonal_factor) * 0.3\n",
    "                adjusted_forecast.append(max(adjusted_value, 0))\n",
    "            \n",
    "            forecast = np.array(adjusted_forecast)\n",
    "        \n",
    "        # Ensure non-negative forecasts\n",
    "        forecast = np.maximum(forecast, 0)\n",
    "        \n",
    "        return forecast, model_fit\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA failed for {sku_name}: {e}\")\n",
    "        # Fallback to seasonal average\n",
    "        if len(train_data) >= 3:\n",
    "            recent_avg = train_data['수량'].iloc[-3:].mean()\n",
    "        else:\n",
    "            recent_avg = train_data['수량'].mean()\n",
    "        \n",
    "        # Apply growth trend\n",
    "        forecast = []\n",
    "        for i in range(forecast_months):\n",
    "            if sku_name == 'VIT-C-1000':\n",
    "                # For VIT-C-1000, ensure August-October predictions are reasonable\n",
    "                month_multiplier = [1.1, 1.05, 1.0][i] if i < 3 else 1.0\n",
    "            else:\n",
    "                month_multiplier = 1.0\n",
    "            forecast.append(recent_avg * month_multiplier)\n",
    "        \n",
    "        return np.array(forecast), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Prophet Model Training (keep existing)\n",
    "def train_prophet(train_data, forecast_months):\n",
    "    \"\"\"Train Prophet model and generate forecasts\"\"\"\n",
    "    try:\n",
    "        # Prepare data for Prophet\n",
    "        prophet_data = train_data[['날짜', '수량']].copy()\n",
    "        prophet_data.columns = ['ds', 'y']\n",
    "        \n",
    "        # Initialize and fit model\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            changepoint_prior_scale=0.1,\n",
    "            seasonality_prior_scale=10.0\n",
    "        )\n",
    "        model.fit(prophet_data)\n",
    "        \n",
    "        # Create future dataframe\n",
    "        future = model.make_future_dataframe(periods=forecast_months, freq='MS')\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # Extract predictions for forecast period\n",
    "        forecast_values = forecast.iloc[-forecast_months:]['yhat'].values\n",
    "        \n",
    "        return forecast_values, model\n",
    "    except Exception as e:\n",
    "        print(f\"Prophet failed: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Evaluation (keep existing)\n",
    "def evaluate_model(actual, predicted):\n",
    "    \"\"\"Calculate evaluation metrics\"\"\"\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    # Custom MAPE calculation to handle zeros\n",
    "    mask = actual != 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100\n",
    "    else:\n",
    "        mape = np.inf if predicted.sum() > 0 else 0\n",
    "    \n",
    "    # Symmetric MAPE\n",
    "    smape = np.mean(2 * np.abs(actual - predicted) / (np.abs(actual) + np.abs(predicted) + 1e-8)) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'sMAPE': smape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING IMPROVED MODELS WITH MONTHLY SEASONALITY\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: VIT-C-1000\n",
      "Data info: 6 months available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\anaconda3\\envs\\playauto\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating future predictions for VIT-C-1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\anaconda3\\envs\\playauto\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: ARIMA\n",
      "ARIMA predictions: [226.53371503 370.72883381 341.11099091]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: OMEGA-3-500\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for OMEGA-3-500...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [349.16568693 348.70164377 348.88637266]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: PROBIO-10B\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for PROBIO-10B...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [345.04689077 349.15341687 348.26366541]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: VIT-D-5000\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for VIT-D-5000...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [360.8225715  374.15621389 380.54620625]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: CALCIUM-MAG\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for CALCIUM-MAG...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [445.95182674 443.23928353 443.07224163]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: ZINC-15\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for ZINC-15...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [467.99032765 472.92796681 472.49724949]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: COLLAGEN-1K\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for COLLAGEN-1K...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [339.13038696 338.51158432 338.5740464 ]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: LUTEIN-20\n",
      "Data info: 6 months available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\anaconda3\\envs\\playauto\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\grego\\anaconda3\\envs\\playauto\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating future predictions for LUTEIN-20...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [323.68207907 321.5832892  321.11055296]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: IRON-18\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for IRON-18...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [322.82044901 306.64001265 298.50420862]\n",
      "\n",
      "==================================================\n",
      "Training models for SKU: MULTI-VIT\n",
      "Data info: 6 months available\n",
      "\n",
      "Generating future predictions for MULTI-VIT...\n",
      "Best model: ARIMA\n",
      "ARIMA predictions: [386.97208837 364.17166437 375.23907382]\n"
     ]
    }
   ],
   "source": [
    "# 7. Train models for each SKU\n",
    "model_results = {}\n",
    "trained_models = {}\n",
    "future_predictions = {}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING IMPROVED MODELS WITH MONTHLY SEASONALITY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for sku, data in sku_data_monthly.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training models for SKU: {sku}\")\n",
    "    \n",
    "    model_results[sku] = {}\n",
    "    trained_models[sku] = {}\n",
    "    future_predictions[sku] = {}\n",
    "    \n",
    "    # Check data availability\n",
    "    print(f\"Data info: {len(data)} months available\")\n",
    "    \n",
    "    # For monthly data, we'll predict 3 months ahead\n",
    "    forecast_months = 3\n",
    "    \n",
    "    # Split data (keep last 3 months for testing if we have enough data)\n",
    "    if len(data) > 6:\n",
    "        train, test = train_test_split_ts(data, test_months=3)\n",
    "    else:\n",
    "        train = data\n",
    "        test = pd.DataFrame()\n",
    "    \n",
    "    # Train ARIMA with seasonal components\n",
    "    arima_forecast, arima_model = train_arima_seasonal(train, forecast_months, sku)\n",
    "    \n",
    "    # # Train Prophet\n",
    "    # prophet_forecast, prophet_model = train_prophet(train, forecast_months)\n",
    "    \n",
    "    # Store models\n",
    "    trained_models[sku] = {\n",
    "        'arima_model': arima_model,\n",
    "        # 'prophet_model': prophet_model\n",
    "    }\n",
    "    \n",
    "    # Evaluate if we have test data\n",
    "    if len(test) > 0:\n",
    "        actual = test['수량'].values\n",
    "        \n",
    "        results = {\n",
    "            'train_size': len(train),\n",
    "            'test_size': len(test)\n",
    "        }\n",
    "        \n",
    "        if arima_forecast is not None:\n",
    "            arima_metrics = evaluate_model(actual[:len(arima_forecast)], arima_forecast[:len(actual)])\n",
    "            results['arima'] = {\n",
    "                'metrics': arima_metrics,\n",
    "                'forecast': arima_forecast\n",
    "            }\n",
    "            print(f\"ARIMA - MAPE: {arima_metrics['MAPE']:.2f}%, RMSE: {arima_metrics['RMSE']:.2f}\")\n",
    "        \n",
    "        # if prophet_forecast is not None:\n",
    "        #     prophet_metrics = evaluate_model(actual[:len(prophet_forecast)], prophet_forecast[:len(actual)])\n",
    "        #     results['prophet'] = {\n",
    "        #         'metrics': prophet_metrics,\n",
    "        #         'forecast': prophet_forecast\n",
    "        #     }\n",
    "        #     print(f\"Prophet - MAPE: {prophet_metrics['MAPE']:.2f}%, RMSE: {prophet_metrics['RMSE']:.2f}\")\n",
    "        \n",
    "        model_results[sku] = results\n",
    "    \n",
    "    # Generate future predictions using all data\n",
    "    print(f\"\\nGenerating future predictions for {sku}...\")\n",
    "    \n",
    "    # Train on all data\n",
    "    final_arima_forecast, _ = train_arima_seasonal(data, forecast_months, sku)\n",
    "    # final_prophet_forecast, _ = train_prophet(data, forecast_months)\n",
    "    \n",
    "    # Determine best model\n",
    "    if sku in model_results and 'arima' in model_results[sku] and 'prophet' in model_results[sku]:\n",
    "        arima_mape = model_results[sku]['arima']['metrics']['MAPE']\n",
    "        prophet_mape = model_results[sku]['prophet']['metrics']['MAPE']\n",
    "        best_model = 'arima' if arima_mape < prophet_mape else 'prophet'\n",
    "    else:\n",
    "        best_model = 'arima'  # Default\n",
    "    \n",
    "    # Store predictions\n",
    "    future_predictions[sku] = {\n",
    "        'arima': final_arima_forecast,\n",
    "        # 'prophet': final_prophet_forecast,\n",
    "        'best_model': best_model,\n",
    "        'last_date': data['날짜'].max(),\n",
    "        'forecast_months': ['August 2025', 'September 2025', 'October 2025']\n",
    "    }\n",
    "    \n",
    "    print(f\"Best model: {best_model.upper()}\")\n",
    "    print(f\"ARIMA predictions: {final_arima_forecast}\")\n",
    "    # if final_prophet_forecast is not None:\n",
    "    #     print(f\"Prophet predictions: {final_prophet_forecast}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Saving improved models and results...\n"
     ]
    }
   ],
   "source": [
    "# 9. Save improved models and results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Saving improved models and results...\")\n",
    "\n",
    "# Create models directory\n",
    "import os\n",
    "os.makedirs('models_improved', exist_ok=True)\n",
    "\n",
    "# Save trained models\n",
    "with open('models_improved/trained_models.pkl', 'wb') as f:\n",
    "    pickle.dump(trained_models, f)\n",
    "\n",
    "# Save predictions\n",
    "with open('models_improved/future_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(future_predictions, f)\n",
    "\n",
    "# Save evaluation results\n",
    "with open('models_improved/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed report for VIT-C-1000\n",
    "if 'VIT-C-1000' in future_predictions:\n",
    "    vitc_report = {\n",
    "        'SKU': 'VIT-C-1000',\n",
    "        'Historical_Avg': sku_data_monthly['VIT-C-1000']['수량'].mean(),\n",
    "        'Last_Month_Value': sku_data_monthly['VIT-C-1000']['수량'].iloc[-1],\n",
    "        'Aug_Prediction': future_predictions['VIT-C-1000']['arima'][0],\n",
    "        'Sep_Prediction': future_predictions['VIT-C-1000']['arima'][1],\n",
    "        'Oct_Prediction': future_predictions['VIT-C-1000']['arima'][2],\n",
    "        'Total_Q3_Prediction': future_predictions['VIT-C-1000']['arima'].sum(),\n",
    "        'Best_Model': future_predictions['VIT-C-1000']['best_model']\n",
    "    }\n",
    "    \n",
    "    report_df = pd.DataFrame([vitc_report])\n",
    "    report_df.to_csv('models_improved/vitc_prediction_report.csv', index=False)\n",
    "\n",
    "print(\"\\nImproved training completed!\")\n",
    "print(f\"Models saved to 'models_improved/' directory\")\n",
    "print(f\"VIT-C-1000 report saved to 'models_improved/vitc_prediction_report.csv'\")\n",
    "\n",
    "# Close database connection\n",
    "conn_ps.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 종료\n",
    "cursor_ps.close()\n",
    "conn_ps.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playauto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
